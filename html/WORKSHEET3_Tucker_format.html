
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Tucker format</title><meta name="generator" content="MATLAB 9.0"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2017-06-03"><meta name="DC.source" content="WORKSHEET3_Tucker_format.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Tucker format</h1><!--introduction--><p><i>Written by Sebastian Kraemer, IGPM at RWTH Aachen University</i></p><p><i>The Tucker decomposition is named after Ledyard R. Tucker (1966).</i></p><p>The Tucker format is a further generalization of a matrix low rank decomposition. It is, like the CP format, symmetric regarding its modes.</p><p><img src="WORKSHEET3_Tucker_format_eq01242321273227474292.png" alt="$$ $$ The Tucker-rank $r \in R^d$ is in principle easy to calculate since $$&#xA;$$"></p><p><img src="WORKSHEET3_Tucker_format_eq16859882393891777799.png" alt="$$ r_{\mu}(T) = \mathrm{Tucker-rank}_{\mu}(T) = \mathrm{rank}(T^{(\mu)}), $$"></p><p><img src="WORKSHEET3_Tucker_format_eq08623026184171688794.png" alt="$$ $$ where the matrix $$ T^{(\mu)} $$ is defined via (using Matlab code)&#xA;$$ $$"></p><p><img src="WORKSHEET3_Tucker_format_eq12862620589923148526.png" alt="$$ T^{(\mu)} :=&#xA;{\tt&#xA;reshape(  permute(T,[mu,1:mu-1,mu+1:d])&#xA;,[n(mu),prod(n(1:mu-1))*prod(n(mu+1:d))])}.&#xA;$$"></p><p><img src="WORKSHEET3_Tucker_format_eq14474194042975515548.png" alt="$$ $$ It then follows that there exist $$ $$"></p><p><img src="WORKSHEET3_Tucker_format_eq01605199670387068578.png" alt="$$ U_\mu \in R^{n_{\mu} \times r_{\mu}},$ orthogonal, $\mu = 1,\ldots,d $$ and $$ C \in R^{r_1 \times \ldots \times r_d} $$ such that $$ T = C \times_{n=1}^N U_{\mu}. $$"></p><p><img src="WORKSHEET3_Tucker_format_eq17844334918324823254.png" alt="$$ $$ This $$ \mathrm{\mu-mode} $$ product is defined via $$ (C \times_{\mu} U_{\mu})^{(\mu)} = U_{\mu} C^{(\mu)}. $$"></p><p><img src="WORKSHEET3_Tucker_format_eq00076392151127341295.png" alt="$$ U $$ and $C$ are explicitly given: for each $$\mu$ it holds&#xA;$$\mathrm{image}(U_\mu) = \mathrm{image}(T^{(\mu)})$. Furthermore, $$C = T&#xA;\times_{n=1}^N U^T_{\mu}.$$"></p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#2">Matlab: size</a></li><li><a href="#3">EXERCISE 1: mu_mode_prod</a></li><li><a href="#6">Associativity</a></li><li><a href="#7">EXERCISE 2: commutativity</a></li><li><a href="#8">SOLUTION 2</a></li><li><a href="#9">Constructing the full tensor</a></li><li><a href="#10">EXERCISE 3: entrywise evaluation</a></li><li><a href="#11">SOLUTION:</a></li><li><a href="#12">EXERCISE 4: comparison to CP</a></li><li><a href="#13">Norm of a Tucker tensor</a></li><li><a href="#14">EXERCISE* 5: hadamard product</a></li></ul></div><pre class="codeinput">clear <span class="string">all</span> <span class="comment">% this clears all variables of their values</span>
</pre><h2>Matlab: size<a name="2"></a></h2><p>While this has previously not been an issue, one should note that the size function may not capture mode sizes equal to 1. This is a slightly weird behaviour of Matlab. We will hence have to use the dimension d as input parameter.</p><pre class="codeinput">size(rand(1,1,2,1))
size(rand(2,1,1,1))
size(rand(2,1,1))
</pre><pre class="codeoutput">
ans =

     1     1     2


ans =

     2     1


ans =

     2     1

</pre><h2>EXERCISE 1: mu_mode_prod<a name="3"></a></h2><p>Complete the following function mu_mode_prod. As input, it receives a d-dimensional tensor T and a matrix A, as well as an index mu. The output should be the tensor</p><p><img src="WORKSHEET3_Tucker_format_eq05041578979864113192.png" alt="$$ T_{new} = T \times_{\mu} A_{\mu}. $$"></p><pre class="codeinput">T1 = zeros(2,3,2);
d = 3;
T1(:) = 1:2*3*2;
</pre><pre class="codeinput">A1 = zeros(3,2);
A1(:) = 3*2:-1:1
A3 = zeros(4,2);
A3(:) = 1:4*2
</pre><pre class="codeoutput">
A1 =

     6     3
     5     2
     4     1


A3 =

     1     5
     2     6
     3     7
     4     8

</pre><pre class="codeinput">T1_new1 = mu_mode_prod(T1,d,A1,1)
<span class="keyword">if</span> ~isequal(T1_new1,<span class="string">'ANSWER 1 MISSING'</span>)
    sizeT1_new1 = size(T1_new1)
    T1_orig1 = mu_mode_prod(T1_new1,d,pinv(A1),1) <span class="comment">% this should be the original tensor</span>

    T1_new3 = mu_mode_prod(T1,d,A3,3)
    sizeT1_new3 = size(T1_new3)
    T1_orig3 = mu_mode_prod(T1_new3,d,pinv(A3),3) <span class="comment">% this should be the original tensor</span>
<span class="keyword">end</span>
</pre><pre class="codeoutput">
T1_new1 =

ANSWER 1 MISSING

</pre><h2>Associativity<a name="6"></a></h2><p>The mu-mode product is associative (this is quite easy to verify in general):</p><pre class="codeinput">B1 = rand(2,2);
B2 = rand(2,2);
mu_mode_prod(mu_mode_prod(T1,d,B1,1),d,B2,1)
mu_mode_prod(T1,d,B2*B1,1)
</pre><pre class="codeoutput">
ans =

ANSWER 1 MISSING


ans =

ANSWER 1 MISSING

</pre><h2>EXERCISE 2: commutativity<a name="7"></a></h2><p><img src="WORKSHEET3_Tucker_format_eq10129459644791575309.png" alt="$$ $$ Let $$\mu, \nu$$ be fix. When does $$ (T \times_{\mu} A) \times_{\nu}&#xA;B $$ commute? $$ $$"></p><p><img src="WORKSHEET3_Tucker_format_eq09842337586637823883.png" alt="$$ $$ How does this relate to products of the form $$ A \cdot C \cdot B $$ for a matrix $C$ ? $$ $$"></p><h2>SOLUTION 2<a name="8"></a></h2><pre class="codeinput"><span class="string">'ANSWER 2 MISSING'</span>;
</pre><h2>Constructing the full tensor<a name="9"></a></h2><p>With the mu-mode product, it is easy to construct the full tensor. You can use the function Tucker_to_full_tensor to do this:</p><pre class="language-matlab"><span class="keyword">function</span> C = Tucker_to_full_tensor(d,C,U)
</pre><pre class="language-matlab"><span class="keyword">for</span> mu = 1:d
    C = mu_mode_prod(C,d,U{mu},mu);
<span class="keyword">end</span>
</pre><pre class="language-matlab"><span class="keyword">end</span>
</pre><pre class="codeinput">C = rand(2,2,1);
[U1,~] = qr(rand(3,2),0);
size(U1)
U1'*U1
[U2,~] = qr(rand(4,2),0);
[U3,~] = qr(rand(3,1),0);

T2 = Tucker_to_full_tensor(d,C,{U1,U2,U3});
<span class="keyword">if</span> ~isequal(T2,<span class="string">'ANSWER 1 MISSING'</span>)
    T2(1,1,1)
<span class="keyword">end</span>
</pre><pre class="codeoutput">
ans =

     3     2


ans =

    1.0000    0.0000
    0.0000    1.0000

</pre><h2>EXERCISE 3: entrywise evaluation<a name="10"></a></h2><p>How can one, without unnecessary computations, evaluate one single entry of a tensor given in the Tucker format? Use the upper tensor T2 to verify your answer.</p><pre class="codeinput">I = [2,3,1];
<span class="keyword">if</span> ~isequal(T2,<span class="string">'ANSWER 1 MISSING'</span>)
    T2(2,3,1)
<span class="keyword">end</span>
</pre><h2>SOLUTION:<a name="11"></a></h2><pre class="codeinput"><span class="string">'ANSWER 3 MISSING'</span>;
</pre><h2>EXERCISE 4: comparison to CP<a name="12"></a></h2><p>As we have seen, the CP format has several weakspots from a practical point of view (it does however have certain interesting theoretical aspects to be fair). Recall its properties and compare these to the Tucker format. What might be a weakspot of the Tucker format?</p><h2>Norm of a Tucker tensor<a name="13"></a></h2><p>Many operations can be applied to tensors if they are given in low rank formats, such as Tucker, without ever constructing the full tensor (this is nearly the hole point of these formats). For example (why does this hold?):</p><pre class="codeinput"><span class="keyword">if</span> ~isequal(T2,<span class="string">'ANSWER 1 MISSING'</span>)
    norm(C(:))
    norm(T2(:))
<span class="keyword">end</span>
</pre><h2>EXERCISE* 5: hadamard product<a name="14"></a></h2><p>Complete the following function Tucker_hadamard_prod. The function itself is <b>not</b> allowed to construct any full tensor. As input it expects two Tucker representations (C,U) and (S,Q) of two tensors, respectively. The output (W,P) is the representation of the tensor H_I defined as the hadamard product of these two input tensors, i.e.</p><p><img src="WORKSHEET3_Tucker_format_eq15649640446507091441.png" alt="$$ H_I := (C \times_{\mu=1}^N U_{\mu})_I \cdot (S \times_{\mu=1}^N&#xA;Q_{\mu})_I, \quad H_I = (W \times_{\mu=1}^N P_{\mu})_I, \quad \forall I = (i_1,\ldots,i_d), $$"></p><p>Both tensors have to be of the same size (yet not same rank). The output tensor also shares mode size and dimension. But what about its rank?</p><pre class="codeinput">d = randi([3,5],1)
n = randi([3,4],1,d)
</pre><pre class="codeoutput">
d =

     4


n =

     3     4     3     4

</pre><pre class="codeinput">rC = n - randi([1,2],1,d) <span class="comment">% first random representation</span>
C = randn(rC);
U = cell(1,d);
<span class="keyword">for</span> mu = 1:d
    [U{mu},~] = qr(rand(n(mu),rC(mu)),0);
<span class="keyword">end</span>
</pre><pre class="codeoutput">
rC =

     1     3     1     2

</pre><pre class="codeinput">rS = n - randi([1,2],1,d) <span class="comment">% second random representation</span>
S = randn(rS);
Q = cell(1,d);
<span class="keyword">for</span> mu = 1:d
    [Q{mu},~] = qr(rand(n(mu),rS(mu)),0);
<span class="keyword">end</span>
</pre><pre class="codeoutput">
rS =

     1     3     1     3

</pre><pre class="codeinput">T2 = Tucker_to_full_tensor(d,C,U); <span class="comment">% first full tensor</span>
T3 = Tucker_to_full_tensor(d,S,Q); <span class="comment">% second full tensor</span>
H = T2.*T3; <span class="comment">% this performs the hadamard product</span>
</pre><pre class="codeinput">[W,Q] = Tucker_hadamard_prod(d,C,U,S,Q); <span class="comment">% now first without full tensors</span>
<span class="keyword">if</span> ~isequal(<span class="string">'ANSWER 5 MISSING'</span>,W)
    H_I = H(2,2,1)
    H_WQ = Tucker_to_full_tensor(d,W,Q);
    H_WQ_I = H_WQ(2,2,1) <span class="comment">% this should be the same</span>
<span class="keyword">else</span>
    <span class="string">'ANSWER 5 MISSING'</span>
<span class="keyword">end</span>
</pre><pre class="codeoutput">
ans =

ANSWER 5 MISSING

</pre><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2016a</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Tucker format
% _Written by Sebastian Kraemer, IGPM at RWTH Aachen University_
%
% _The Tucker decomposition is named after Ledyard R. Tucker (1966)._
%
% The Tucker format is a further generalization of a
% matrix low rank decomposition. It is, like the CP format, symmetric
% regarding its modes.
%
% $$ $$ The Tucker-rank $r \in R^d$ is in principle easy to calculate since $$
% $$
%
% $$ r_{\mu}(T) = \mathrm{Tucker-rank}_{\mu}(T) = \mathrm{rank}(T^{(\mu)}), $$
%
% $$ $$ where the matrix $$ T^{(\mu)} $$ is defined via (using Matlab code)
% $$ $$
%
% $$ T^{(\mu)} :=
% {\tt
% reshape(  permute(T,[mu,1:mu-1,mu+1:d])
% ,[n(mu),prod(n(1:mu-1))*prod(n(mu+1:d))])}.
% $$
%
% $$ $$ It then follows that there exist $$ $$
%
% $$ U_\mu \in R^{n_{\mu} \times r_{\mu}},$ orthogonal, $\mu = 1,\ldots,d $$ and $$ C \in R^{r_1 \times \ldots \times r_d} $$ such that $$ T = C \times_{n=1}^N U_{\mu}. $$
%
% $$ $$ This $$ \mathrm{\mu-mode} $$ product is defined via $$ (C \times_{\mu} U_{\mu})^{(\mu)} = U_{\mu} C^{(\mu)}. $$
%
% $$ U $$ and $C$ are explicitly given: for each $$\mu$ it holds
% $$\mathrm{image}(U_\mu) = \mathrm{image}(T^{(\mu)})$. Furthermore, $$C = T
% \times_{n=1}^N U^T_{\mu}.$$
%%
clear all % this clears all variables of their values

%% Matlab: size
% While this has previously not been an issue, one should note that the
% size function may not capture mode sizes equal to 1. This is a slightly 
% weird behaviour of Matlab. 
% We will hence have to use the dimension d as input parameter.
size(rand(1,1,2,1))
size(rand(2,1,1,1))
size(rand(2,1,1))

%% EXERCISE 1: mu_mode_prod
% Complete the following function mu_mode_prod. As input, it receives a
% d-dimensional tensor T and a matrix A, as well as an index mu.
% The output should be the tensor
%
% $$ T_{new} = T \times_{\mu} A_{\mu}. $$
T1 = zeros(2,3,2);
d = 3;
T1(:) = 1:2*3*2;
%%
A1 = zeros(3,2);
A1(:) = 3*2:-1:1
A3 = zeros(4,2);
A3(:) = 1:4*2
%%
T1_new1 = mu_mode_prod(T1,d,A1,1)
if ~isequal(T1_new1,'ANSWER 1 MISSING')
    sizeT1_new1 = size(T1_new1)
    T1_orig1 = mu_mode_prod(T1_new1,d,pinv(A1),1) % this should be the original tensor
    
    T1_new3 = mu_mode_prod(T1,d,A3,3)
    sizeT1_new3 = size(T1_new3)
    T1_orig3 = mu_mode_prod(T1_new3,d,pinv(A3),3) % this should be the original tensor
end

%% Associativity
% The mu-mode product is associative (this is quite easy to verify in
% general):
B1 = rand(2,2);
B2 = rand(2,2);
mu_mode_prod(mu_mode_prod(T1,d,B1,1),d,B2,1)
mu_mode_prod(T1,d,B2*B1,1)

%% EXERCISE 2: commutativity
% $$ $$ Let $$\mu, \nu$$ be fix. When does $$ (T \times_{\mu} A) \times_{\nu}
% B $$ commute? $$ $$
%
% $$ $$ How does this relate to products of the form $$ A \cdot C \cdot B $$ for a matrix $C$ ? $$ $$

%% SOLUTION 2
'ANSWER 2 MISSING';

%% Constructing the full tensor
% With the mu-mode product, it is easy to construct the full tensor. You
% can use the function Tucker_to_full_tensor to do this:
%
%   function C = Tucker_to_full_tensor(d,C,U)
% 
%   for mu = 1:d
%       C = mu_mode_prod(C,d,U{mu},mu);
%   end
% 
%   end
C = rand(2,2,1);
[U1,~] = qr(rand(3,2),0);
size(U1)
U1'*U1
[U2,~] = qr(rand(4,2),0);
[U3,~] = qr(rand(3,1),0);

T2 = Tucker_to_full_tensor(d,C,{U1,U2,U3}); 
if ~isequal(T2,'ANSWER 1 MISSING')
    T2(1,1,1)
end

%% EXERCISE 3: entrywise evaluation
% How can one, without unnecessary computations, evaluate one single entry
% of a tensor given in the Tucker format? Use the upper tensor T2 to verify
% your answer.
I = [2,3,1];
if ~isequal(T2,'ANSWER 1 MISSING')
    T2(2,3,1)
end

%% SOLUTION:
'ANSWER 3 MISSING';

%% EXERCISE 4: comparison to CP
% As we have seen, the CP format has several weakspots from a practical
% point of view (it does however have certain interesting theoretical
% aspects to be fair). Recall its properties and compare these to the
% Tucker format. What might be a weakspot of the Tucker format?

%% Norm of a Tucker tensor
% Many operations can be applied to tensors if they are given in low rank
% formats, such as Tucker, without ever constructing the full tensor (this
% is nearly the hole point of these formats). For example (why does this hold?):
if ~isequal(T2,'ANSWER 1 MISSING')
    norm(C(:))
    norm(T2(:))
end

%% EXERCISE* 5: hadamard product
% Complete the following function Tucker_hadamard_prod. The function itself is *not* allowed to construct any full tensor.
% As input it expects
% two Tucker representations (C,U) and (S,Q) of two tensors, respectively. The output (W,P) is the representation of
% the tensor H_I defined as the hadamard product of these two input tensors, i.e.
%
% $$ H_I := (C \times_{\mu=1}^N U_{\mu})_I \cdot (S \times_{\mu=1}^N
% Q_{\mu})_I, \quad H_I = (W \times_{\mu=1}^N P_{\mu})_I, \quad \forall I = (i_1,\ldots,i_d), $$
%
% Both tensors have to be of the same size (yet not same rank). The output
% tensor also shares mode size and dimension. But what about its rank?
%
% 
d = randi([3,5],1)
n = randi([3,4],1,d)
%%
rC = n - randi([1,2],1,d) % first random representation
C = randn(rC);
U = cell(1,d);
for mu = 1:d
    [U{mu},~] = qr(rand(n(mu),rC(mu)),0);
end
%%
rS = n - randi([1,2],1,d) % second random representation
S = randn(rS);
Q = cell(1,d);
for mu = 1:d
    [Q{mu},~] = qr(rand(n(mu),rS(mu)),0);
end
%%
T2 = Tucker_to_full_tensor(d,C,U); % first full tensor
T3 = Tucker_to_full_tensor(d,S,Q); % second full tensor
H = T2.*T3; % this performs the hadamard product
%%
[W,Q] = Tucker_hadamard_prod(d,C,U,S,Q); % now first without full tensors
if ~isequal('ANSWER 5 MISSING',W)
    H_I = H(2,2,1)
    H_WQ = Tucker_to_full_tensor(d,W,Q);
    H_WQ_I = H_WQ(2,2,1) % this should be the same
else
    'ANSWER 5 MISSING'
end









##### SOURCE END #####
--></body></html>